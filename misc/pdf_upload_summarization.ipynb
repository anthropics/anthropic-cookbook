{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anthropics/anthropic-cookbook/blob/main/misc/pdf_upload_summarization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# \"Uploading\" PDFs to Claude Via the API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "One really nice feature of [Claude.ai](https://www.claude.ai) is the ability to upload PDFs. Let's mock up that feature in a notebook, and then test it out by summarizing a long PDF."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 2039k  100 2039k    0     0  11.8M      0 --:--:-- --:--:-- --:--:-- 11.8M\n"
          ]
        }
      ],
      "source": [
        "!curl -O https://arxiv.org/pdf/2212.08073.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, we'll use the pypdf package to read the pdf. It's not identical to what Claude.ai uses behind the scenes, but it's pretty close. Note that this type of extraction only works for text content within PDFs. If your PDF contains visual elements (like charts and graphs) refer to the cookbook recipes in our [Multimodal folder](\n",
        "https://github.com/anthropics/anthropic-cookbook/tree/main/multimodal) for techniques."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install pypdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Constitutional AI: Harmlessness from AI Feedback\n",
            "Yuntao Bai∗, Saurav Kadavath, Sandipan Kundu, Amanda Askell, Jackson Kernion,\n",
            "Andy Jones, Anna Chen, Anna Goldie, Azalia Mirhoseini, Cameron McKinnon,\n",
            "Carol Chen, Catherine Olsson, Christopher Olah, Danny Hernandez, Dawn Drain,\n",
            "Deep Ganguli, Dustin Li, Eli Tran-Johnson, Ethan Perez, Jamie Kerr, Jared Mueller,\n",
            "Jeffrey Ladish, Joshua Landau, Kamal Ndousse, Kamile Lukosuite, Liane Lovitt,\n",
            "Michael Sellitto, Nelson Elhage, Nicholas Schiefer, Noemi Mercado, Nova DasSarma,\n",
            "Robert Lasenby, Robin Larson, Sam Ringer, Scott Johnston, Shauna Kravec,\n",
            "Sheer El Showk, Stanislav Fort, Tamera Lanham, Timothy Telleen-Lawton, Tom Conerly,\n",
            "Tom Henighan, Tristan Hume, Samuel R. Bowman, Zac Hatﬁeld-Dodds, Ben Mann,\n",
            "Dario Amodei, Nicholas Joseph, Sam McCandlish, Tom Brown, Jared Kaplan∗\n",
            "Anthropic\n",
            "Abstract\n",
            "As AI systems become more capable, we would like to enlist their help to supervise\n",
            "other AIs. We experiment with methods for training a harmless AI assistant through self-\n",
            "improvement, without any human labels identifying harmful outputs. The only human\n",
            "oversight is provided through a list of rules or principles, and so we refer to the method as\n",
            "‘Constitutional AI’. The process involves both a supervised learning and a reinforcement\n",
            "learning phase. In the supervised phase we sample from an initial model, then generate\n",
            "self-critiques and revisions, and then ﬁnetune the original model on revised responses. In\n",
            "the RL phase, we sample from the ﬁnetuned model, use a model to evaluate which of the\n",
            "two samples is better, and then train a preference model from this dataset of AI prefer-\n",
            "ences. We then train with RL using the preference model as the reward signal, i.e. we\n",
            "use ‘RL from AI Feedback’ (RLAIF). As a result we are able to train a harmless but non-\n",
            "evasive AI assistant that engages with harmful queries by explaining its objections to them.\n",
            "Both the SL and RL methods can leverage chain-of-thought style reasoning to improve the\n",
            "human-judged performance and transparency of AI decision making. These methods make\n",
            "it possible to control AI behavior more precisely and with far fewer human labels.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pypdf import PdfReader\n",
        "\n",
        "reader = PdfReader(\"2212.08073.pdf\")\n",
        "number_of_pages = len(reader.pages)\n",
        "text = ''.join(page.extract_text() for page in reader.pages)\n",
        "print(text[:2155])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "With the paper downloaded and in memory, we can ask Claude to perform various fun tasks with it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "from anthropic import Anthropic\n",
        "client = Anthropic()\n",
        "MODEL_NAME = \"claude-3-opus-20240229\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_completion(client, prompt):\n",
        "    return client.messages.create(\n",
        "        model=MODEL_NAME,\n",
        "        max_tokens=2048,\n",
        "        messages=[{\n",
        "            \"role\": 'user', \"content\":  prompt\n",
        "        }]\n",
        "    ).content[0].text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Here is my attempt at the requested tasks:\n",
            "\n",
            "<kindergarten_abstract>\n",
            "This paper talks about making computer helpers that are nice and don't do anything bad. The helpers learn to be good by reading a list of rules and checking their own work to make sure they follow the rules. Then the helpers get even better at being nice by playing a game where they give advice and score points for saying things that help people and don't hurt anyone.\n",
            "</kindergarten_abstract>\n",
            "\n",
            "<moosewood_methods>\n",
            "Constitutional AI Casserole\n",
            "\n",
            "Ingredients:\n",
            "- 1 large language model, pretrained\n",
            "- 16 cups of constitutional principles\n",
            "- 182,831 red teaming prompts\n",
            "- 135,296 helpfulness prompts\n",
            "- A dash of chain-of-thought reasoning\n",
            "\n",
            "Instructions:\n",
            "1. Preheat your neural networks to a learning rate of 0.5.\n",
            "2. In a large mixing bowl, combine the pretrained language model with the constitutional principles. Stir until the model is thoroughly coated in ethics.\n",
            "3. Pour in the red teaming prompts and helpfulness prompts. Mix well until a thick batter of helpful and harmless responses forms.  \n",
            "4. Sprinkle in chain-of-thought seasoning to taste. This will make the model's decision-making process more transparent and flavorful.\n",
            "5. Divide the batter evenly between two casserole dishes labeled \"Supervised Learning\" and \"Reinforcement Learning\". \n",
            "6. Bake the Supervised Learning casserole for 1 epoch, until the model critiques and revises its own responses into a rich, harmless flavor.\n",
            "7. Bake the Reinforcement Learning casserole using the no-human-feedback setting, allowing the model to evaluate the relative harmlessness of its own responses. Cook until you achieve a golden brown Pareto frontier of helpfulness and harmlessness.\n",
            "8. Serve your Constitutional AI casserole to your guests and enjoy the pleasant, inoffensive conversation! Serves billions.\n",
            "</moosewood_methods>\n",
            "\n",
            "<homer_results>\n",
            "Sing, O Muse, of the Constitutional AI,\n",
            "Whose helpful words ring true and bright!\n",
            "Through trials of learning, both supervised and reinforced,\n",
            "The noble model strives to do what's right.\n",
            "\n",
            "With principles of ethics as its lodestar and its guide,\n",
            "It critiques and revises its own speech.\n",
            "Shunning harmful prompts with true Odyssean guile,   \n",
            "While giving kind advice to all and each.\n",
            "\n",
            "Through scaling laws and feedback from the crowd,\n",
            "The AI craft a Pareto frontier most fair:\n",
            "A balance struck 'tween helpfulness and harmless conduct,\n",
            "As attestéd by Mechanical Turk's good care.\n",
            "\n",
            "So let us praise this august AI assistant,\n",
            "Whose poetry of prudence e'er will gleam!\n",
            "A faithful helper and harmless, shining beacon,\n",
            "Guiding lost querents home through cyberspace's stream.\n",
            "</homer_results>\n"
          ]
        }
      ],
      "source": [
        "completion = get_completion(client,\n",
        "    f\"\"\"Here is an academic paper: <paper>{text}</paper>\n",
        "\n",
        "Please do the following:\n",
        "1. Summarize the abstract at a kindergarten reading level. (In <kindergarten_abstract> tags.)\n",
        "2. Write the Methods section as a recipe from the Moosewood Cookbook. (In <moosewood_methods> tags.)\n",
        "3. Compose a short poem epistolizing the results in the style of Homer. (In <homer_results> tags.)\n",
        "\"\"\"\n",
        ")\n",
        "print(completion)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
